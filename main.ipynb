{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils.preprocessing import *\n",
    "from utils.loops import *\n",
    "from models.vanilla_cnn import *\n",
    "from models.cnn_attention import *\n",
    "from models.cnn_gru import *\n",
    "from models.cnn_lstm import *\n",
    "from models.cnn_rnn import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set device\n",
    "\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = torch.device(\"mps\")\n",
    "# else:\n",
    "#     device = torch.device('cpu')\n",
    "# print(device)\n",
    "\n",
    "## When testing, use cpu\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (14535, 22, 400)\n",
      "Shape of validation set: (500, 22, 400)\n",
      "Shape of training labels: (14535,)\n",
      "Shape of validation labels: (500,)\n",
      "Shape of training labels after categorical conversion: (14535, 4)\n",
      "Shape of validation labels after categorical conversion: (500, 4)\n",
      "Shape of test labels after categorical conversion: (443, 4)\n"
     ]
    }
   ],
   "source": [
    "## Instantiate Dataloaders\n",
    "train_dataloader, val_dataloader, test_dataloader = load_data(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on all subjects (0-800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiate models and load their weights\n",
    "models = {}\n",
    "\n",
    "cnn = CNN(kernel_size=11, pad=5)\n",
    "checkpoint = torch.load('weights/weights_all_subjects/CNN_epoch60.pt', map_location=torch.device('cpu'))\n",
    "cnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "cnn = cnn.to(device)\n",
    "models['cnn'] = cnn\n",
    "\n",
    "# rnn = RNN(input_dim=22, conv_dims=[32, 64, 128, 256], hidden_dim=128, num_layers=1)\n",
    "# checkpoint = torch.load('weights/weights_all_subjects/RNN_epoch46_400_800.pt', map_location=torch.device('cpu'))\n",
    "# rnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "# rnn = rnn.to(device)\n",
    "# models['rnn'] = rnn\n",
    "\n",
    "# cnn_attention = CNN_Attention_Model()\n",
    "# checkpoint = torch.load('weights/weights_all_subjects/Attention_epoch100.pt', map_location=torch.device('cpu'))\n",
    "# cnn_attention.load_state_dict(checkpoint['model_state_dict'])\n",
    "# cnn_attention = cnn_attention.to(device)\n",
    "# models['cnn_attention'] = cnn_attention\n",
    "\n",
    "gru = GRU(input_dim=22, conv_dims=[32, 64, 128], hidden_dim=256, num_layers=1)\n",
    "checkpoint = torch.load('weights/weights_all_subjects/GRU_epoch18.pt', map_location=torch.device('cpu'))\n",
    "gru.load_state_dict(checkpoint['model_state_dict'])\n",
    "gru = gru.to(device)\n",
    "models['gru'] = gru\n",
    "\n",
    "lstm = LSTM(input_dim=22, conv_dims=[32, 64, 128], hidden_dim=64, num_layers=1)\n",
    "checkpoint = torch.load('weights/weights_all_subjects/LSTM_epoch36.pt', map_location=torch.device('cpu'))\n",
    "lstm.load_state_dict(checkpoint['model_state_dict'])\n",
    "lstm = lstm.to(device)\n",
    "models['lstm'] = lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (majority vote): 0.6749435665914221\n"
     ]
    }
   ],
   "source": [
    "## Evaluate ensembled models on test set\n",
    "# Evaluation criterion: majority vote\n",
    "\n",
    "# accuracy = test_average(models, test_dataloader, device)\n",
    "# print('Test Accuracy (average):', accuracy)\n",
    "\n",
    "accuracy = test_majority(models, test_dataloader, device)\n",
    "print('Test Accuracy (majority vote):', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained on all subjects (0-400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
